{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liberias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruta para los csv en data/processed\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Subir un nivel\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"processed\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rand-Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feaure Importance\n",
    "Medimos la importancia de cada variable para ver las que vamosa considerar en nuestro modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_importancia_variables(data_dir):\n",
    "    resultados = {}\n",
    "\n",
    "    # Lista de archivos esperados\n",
    "    file_paths = {\n",
    "        \"v1\": os.path.join(data_dir, \"Propensity_clean_v1.csv\"),\n",
    "        \"v2\": os.path.join(data_dir, \"Propensity_clean_v2.csv\"),\n",
    "        \"v3\": os.path.join(data_dir, \"Propensity_clean_v3.csv\"),\n",
    "        \"v4\": os.path.join(data_dir, \"Propensity_clean_v4.csv\"),\n",
    "    }\n",
    "\n",
    "    for version, path in file_paths.items():\n",
    "        print(f\"\\n游댌 Evaluando importancia de variables en: {version}\")\n",
    "\n",
    "        # Cargar los datos\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # Verificar si la columna \"Mas_1_coche\" est치 presente y eliminar columnas problem치ticas\n",
    "        if \"Mas_1_coche\" in df.columns:\n",
    "            y = df[\"Mas_1_coche\"]\n",
    "            X = df.drop(columns=[\"Mas_1_coche\"], errors=\"ignore\")\n",
    "        # Eliminar columnas no num칠ricas si existen\n",
    "        X = X.select_dtypes(include=['number'])\n",
    "\n",
    "        # Dividir en entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Entrenar un Random Forest b치sico\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # Obtener importancia de variables\n",
    "        importances = rf.feature_importances_\n",
    "        feature_importance_df = pd.DataFrame({\"Variable\": X.columns, \"Importancia\": importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by=\"Importancia\", ascending=False)\n",
    "\n",
    "        # Guardar resultados\n",
    "        resultados[version] = feature_importance_df\n",
    "\n",
    "        # Mostrar la tabla de importancia de variables\n",
    "        display(feature_importance_df)\n",
    "\n",
    "        # Graficar la importancia de las variables\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=\"Importancia\", y=\"Variable\", data=feature_importance_df)\n",
    "        plt.title(f\"Importancia de Variables en Random Forest - {version}\")\n",
    "        plt.show()\n",
    "\n",
    "    return resultados\n",
    "\n",
    "\n",
    "# Ejecutar la funci칩n con la ruta corregida\n",
    "importancia_variables_resultados = evaluar_importancia_variables(DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en cada csv hemos hecho un tratamiento distinto de los nulos , comparamos la importancia de cada variable en cada uno de ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacion_df = pd.DataFrame()\n",
    "\n",
    "for version, df_importance in importancia_variables_resultados.items():\n",
    "    df_importance = df_importance.rename(columns={\"Importancia\": f\"Importancia_{version}\"})\n",
    "    if comparacion_df.empty:\n",
    "        comparacion_df = df_importance\n",
    "    else:\n",
    "        comparacion_df = comparacion_df.merge(df_importance, on=\"Variable\", how=\"outer\")\n",
    "\n",
    "\n",
    "comparacion_df[\"Importancia_Promedio\"] = comparacion_df.drop(columns=[\"Variable\"]).mean(axis=1)\n",
    "comparacion_df = comparacion_df.sort_values(by=\"Importancia_Promedio\", ascending=False)\n",
    "comparacion_df = comparacion_df.drop(columns=[\"Importancia_Promedio\"])\n",
    "\n",
    "display(comparacion_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclusi칩n de la Variable `Tiempo`**\n",
    "\n",
    "Tiempo porque es un par치metro que solo tienen los clientes con una segunda compra. Esto sesga la predicci칩n, ya que no es representativo de todos los clientes, especialmente aquellos que no han realizado una segunda compra. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
